{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0431c3b6-91a7-4c07-906b-32acf3144f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "NB_DIR = os.path.abspath('')\n",
    "\n",
    "# To make any library in nbdir import-able\n",
    "if NB_DIR not in sys.path:\n",
    "    sys.path.append(NB_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cda510b-4990-484a-a759-26db11aba5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, KFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, SGDClassifier, RidgeClassifierCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, \\\n",
    "    GradientBoostingClassifier, HistGradientBoostingClassifier, BaggingClassifier, ExtraTreesClassifier, \\\n",
    "    VotingClassifier, StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- Our own libraries ---\n",
    "\n",
    "import feature_extraction as fe\n",
    "import buffer\n",
    "\n",
    "# Reload automatically upon any change in feature_extraction.py\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48be1e-89ba-4175-aba9-98af26151033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of CPU cores to use in parallel by sklearn\n",
    "# (where possible).\n",
    "N_JOBS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d984e914-e220-4165-be75-3c2b4e7bae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data from file into train_data list\n",
    "\n",
    "train_file_path = os.path.join(NB_DIR, 'data', 'train.jsonl')\n",
    "train_data = []\n",
    "\n",
    "# Read and decode the file line by line\n",
    "print(f\"Loading data from '{train_file_path}'...\")\n",
    "try:\n",
    "    with open(train_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # json.loads() parses one line (one JSON object) into a Python dictionary\n",
    "            train_data.append(json.loads(line))\n",
    "    print(f'Successfully loaded {len(train_data)} battles.')\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find the training file at '{train_file_path}'.\")\n",
    "    print('Please make sure you have added the competition data to this notebook.')\n",
    "\n",
    "except IOError:\n",
    "    print(f\"An error occurred while reading the file '{train_file_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce8b3aa-d1fe-42cf-8ea9-4d0599f6ee25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "# Sneak a peek into the just loaded battle data.\n",
    "\n",
    "MOVES_TO_DISPLAY = 30\n",
    "\n",
    "print(\"\\n--- Structure of the first train battle: ---\")\n",
    "if train_data:\n",
    "    first_battle = train_data[0]\n",
    "    \n",
    "    # To keep the output clean, we can create a copy and truncate the timeline\n",
    "    battle_for_display = first_battle.copy()\n",
    "    battle_for_display['battle_timeline'] = battle_for_display.get('battle_timeline', [])[:MOVES_TO_DISPLAY]\n",
    "    \n",
    "    # Use yaml.dump for pretty-printing the dictionary\n",
    "    print(yaml.dump(battle_for_display, indent=4))\n",
    "    if len(first_battle.get('battle_timeline', [])) > MOVES_TO_DISPLAY:\n",
    "        print(\"    ...\")\n",
    "        print(\"    [battle_timeline has been truncated for display]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c765747-971b-4eef-9452-ba352ecccd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENTS ON PLAYERS STATUSES DURING a BATTLE!\n",
    "import pandas as pd\n",
    "\n",
    "STATUS = 'nostatus'\n",
    "STATUSES = ['nostatus', 'frz', 'par', 'slp', 'fnt', 'tox', 'psn', 'brn']\n",
    "STATUSES_affected = ['frz', 'par', 'slp', 'fnt', 'tox', 'psn', 'brn']\n",
    "\n",
    "battles_ = []\n",
    "for battle in train_data:\n",
    "    player_status_count = {}\n",
    "    for move in battle['battle_timeline']:\n",
    "        if move['p1_move_details'] and move['p2_move_details']:\n",
    "            status_1 = move['p1_pokemon_state']['status']\n",
    "            status_2 = move['p2_pokemon_state']['status']\n",
    "            \n",
    "            player_status_count[f'p1_{status_1}'] = player_status_count.get(f'p1_{status_1}', 0) + 1\n",
    "            player_status_count[f'p2_{status_2}'] = player_status_count.get(f'p2_{status_2}', 0) + 1\n",
    "\n",
    "            # STATUS combinations\n",
    "            #if status_1 == 'nostatus' and status_2 in STATUSES_affected:\n",
    "            #    player_status_count[f'{status_1}_{status_2}'] = player_status_count.get(f'{status_1}_{status_2}', 0) + 1\n",
    "            player_status_count[f'{status_1}_{status_2}'] = player_status_count.get(f'{status_1}_{status_2}', 0) + 1\n",
    "        \n",
    "    player_status_count['winner'] = int(battle['player_won'])\n",
    "    battles_.append(player_status_count)\n",
    "\n",
    "statuses_df = pd.DataFrame(battles_).fillna(0)\n",
    "statuses_df.reindex(sorted(statuses_df.columns), axis=1)\n",
    "reordered_col_names = ['winner'] + sorted(list(statuses_df))[:-1]\n",
    "stat_df = statuses_df[reordered_col_names].astype(int)\n",
    "\n",
    "# Statistics!\n",
    "#for s in STATUSES:\n",
    "#    for battle in battles_\n",
    "\n",
    "len(stat_df.loc[((stat_df['p1_psn'] > stat_df['p2_psn'] ) & (stat_df['winner']==1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf099be-7f39-4615-a3d6-eaa3e52ecf6b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering\n",
    "\n",
    "At this point we have all the training data, decoded from JSON, in the `train_data` list (of nested structures), so it's time to work on the features, through techniques such as features regularization and selection. All the relevant functions are in the `feature_extraction` library (file `feature_extraction.py`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d7edb6-13fd-4101-9510-643dc559d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definition only to call them in batch\n",
    "def extract_features(fun, train_data):\n",
    "    print('Processing training data...', end=' ')\n",
    "    train_df = fun(train_data)\n",
    "    print('Done!')\n",
    "    print(train_df.shape)\n",
    "    return train_df\n",
    "\n",
    "train_df = extract_features(fe.extract_features_minimal, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf3085-3c3f-4466-8875-3141a8f7aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: sneak a peek into the features dataframe.\n",
    "train_df.head()\n",
    "train_df[['nostatus_fnt_diff']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0068240b-527f-4d8d-8b3c-9ce5babe0d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: delete bogus line\n",
    "# https://classroom.google.com/c/MjM1MTYxMzEyMTda/p/ODE1OTEyMTU1OTM3/details?hl=it\n",
    "def remove_bogus_line(train_df, line=4877):\n",
    "    train_df.drop(train_df.index[[line]], inplace=True)\n",
    "    train_df.reset_index(drop=True, inplace=True)\n",
    "    #train_df.tail()\n",
    "    return train_df\n",
    "\n",
    "remove_bogus_line(train_df, 4877)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e7841-a1c7-4bf1-b4da-8b4891bf820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "print(json.dumps(train_data[4877], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaedbf3b-a6f4-49b5-94b3-552820300daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: sneak a peek into text columns.\n",
    "text_cols = [col for col in train_df.columns if 'name' in col or 'type' in col]\n",
    "train_df[text_cols].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da0271-586a-472b-9384-c97facb4f406",
   "metadata": {},
   "source": [
    "# Models Training and Comparison\n",
    "\n",
    "At this point we have all the selected features in to the `train_df` dataframe, so it's time to train the various models on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f751d65c-1618-431f-8c03-a50974c0d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode all the text columns\n",
    "le = LabelEncoder()\n",
    "\n",
    "text_cols = [col for col in train_df.columns if 'name' in col or 'type' in col]\n",
    "for col in text_cols: \n",
    "    train_df[col] = le.fit_transform(train_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83238ef-1c49-4fdd-aa56-6757b50d19b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_X_y(train_df):\n",
    "    # Define our features (X) and target (y)\n",
    "    features = [col for col in train_df.columns if col not in ['battle_id', 'player_won']]\n",
    "    \n",
    "    # Any data scaling/regularization goes here\n",
    "    scaler = StandardScaler().fit(train_df[features])\n",
    "    train_df_scaled = scaler.transform(train_df[features])\n",
    "    \n",
    "    # Chose whether to assign train_data the scaled version or the original one (train_df[features])\n",
    "    X_train = train_df_scaled.copy()\n",
    "    return X_train\n",
    "\n",
    "X_train = define_X_y(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a1f30-509e-455e-87c1-e62afc0ca4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative to the above (no scaling!)\n",
    "X_train = train_df[features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aae8a9-82df-4194-8cae-7510d645f383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: select the k best features\n",
    "X_train_reduced_features = SelectKBest(k=40).fit_transform(X_train, train_df['player_won'])\n",
    "\n",
    "X_train = X_train_reduced_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c08e0f-083a-44aa-9d12-0f5e05373283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data (and decide whether to use scaling or not).\n",
    "def split(X_train, train_df, test_size=0.2, shuffle=True):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, train_df['player_won'], test_size=test_size)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split(X_train, train_df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c4544f-2bb1-464c-b1c4-9f4d88c35fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA (optional)\n",
    "pca = PCA(n_components=30)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55c258-edd1-46bc-ae38-9c0308e86509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models list (just add models with their parameters!)\n",
    "models = [\n",
    "    LogisticRegression(max_iter=10_000),\n",
    "    LogisticRegressionCV(max_iter=10_000),\n",
    "    SGDClassifier(max_iter=10_000, tol=1e-3),\n",
    "    GaussianNB(),\n",
    "    DecisionTreeClassifier(random_state=0, criterion='entropy', max_depth=5),\n",
    "    GradientBoostingClassifier(),\n",
    "    HistGradientBoostingClassifier(max_iter=10_000),\n",
    "    RidgeClassifierCV(),\n",
    "    ExtraTreesClassifier(n_estimators=200, random_state=0),\n",
    "    LinearSVC(random_state=0, dual=False),\n",
    "    RandomForestClassifier(n_estimators=200),\n",
    "    KNeighborsClassifier(n_neighbors=100),\n",
    "    GaussianProcessClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    MLPClassifier(max_iter=10_000)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ceb1b-3a95-4dc2-ac7c-73917619adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model():\n",
    "    models = [\n",
    "        HistGradientBoostingClassifier(max_iter=5_000),\n",
    "    ]\n",
    "    return models\n",
    "\n",
    "models = set_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b673d5-2a36-4cf7-834f-05015e372c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model testing with normal training\n",
    "\n",
    "def test_models(X_train, y_train, X_test, y_test, models):\n",
    "    models_result = []\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "        models_result.append([model.__class__.__name__, score])\n",
    "    \n",
    "    print(best_model, '\\t', best_score)\n",
    "\n",
    "test_models(X_train, y_train, X_test, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88785f91-84a6-4e80-936b-f84affe76958",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table = PrettyTable()\n",
    "results_table.field_names = ['Model Name', 'Accuracy']\n",
    "results_table.align['Model Name'] = 'r'\n",
    "results_table.align['Accuracy'] = 'l'\n",
    "results_table.add_rows(sorted([[result[0], round(result[1]*100, 3)] for result in models_result], key=lambda row: row[1]))\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e813d54-4998-47cf-b0b0-53df6d54603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model testing with cross-validation training - Alternative to the above!\n",
    "models_result_cross = []\n",
    "\n",
    "for model in models:\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=cv, n_jobs=N_JOBS)\n",
    "    print(f'{model.__class__.__name__:<32} mean: {cv_results.mean():.3f}\\tmin: {cv_results.min():.3f}\\tmax: {cv_results.max():.3f}')\n",
    "    models_result_cross.append([model.__class__.__name__, cv_results.mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57b38e2-cf65-4983-a91a-732b9d1da9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = np.abs(best_model.coef_)\n",
    "feature_names = np.array(X_train.feature_names)\n",
    "plt.bar(height=importance, x=feature_names)\n",
    "plt.title(\"Feature importances via coefficients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1754e8-2745-4529-8f05-3273ee4df705",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectFromModel(estimator=HistGradientBoostingClassifier(max_iter=10_000)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a2e96b-aec4-4fff-88d9-9af502aa64f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model = HistGradientBoostingClassifier(max_iter=10_000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e7613a-7d7c-491d-bcf6-ca8df879a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(fitted_model, X_train, y_train, n_repeats=3, random_state=0, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be73588c-0481-4404-bc81-06e2e6aac4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.importances_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e48f06-d911-4b52-80df-718c2659db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the most important features, according to permutation_importance().\n",
    "#('p1_hp_pct_shortage', 'p1_players_with_low_hp_pct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71395ed6-34ac-45e8-8cf8-2c821ed9ebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = fitted_model.coef_\n",
    "features_mask = selector.get_support()\n",
    "print(importance)\n",
    "print(features_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c880487-da4a-43e7-98bf-34e8cbc09c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSEMBLE - Set up estimators (models) to use\n",
    "\n",
    "estimators = [\n",
    "    ('DTC', DecisionTreeClassifier(random_state=0, criterion='entropy', max_depth=6)),\n",
    "    ('LR', LogisticRegression(warm_start=True)),\n",
    "    #('RC', RidgeClassifierCV()),\n",
    "    #('LSVC', LinearSVC(random_state=0, dual=False)),\n",
    "    ('LRCV', LogisticRegressionCV()),\n",
    "    ('ETC', ExtraTreesClassifier(warm_start=True, n_estimators=200, random_state=0)),\n",
    "    ('RFC', RandomForestClassifier(warm_start=True, n_estimators=200)),\n",
    "    ('ABC', AdaBoostClassifier()),\n",
    "    ('GBC', GradientBoostingClassifier(warm_start=True)),\n",
    "    ('HGBC', HistGradientBoostingClassifier(warm_start=True, max_iter=10_000))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dedac8-52a9-4044-a65b-4f6501a076dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSEMBLE - Voting\n",
    "ev_clf = VotingClassifier(estimators=estimators, voting='soft', n_jobs=N_JOBS)\n",
    "ev_clf.fit(X_train, y_train)\n",
    "ev_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f141c-6f4a-474c-b85a-be8d13807cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSEMBLE - Stacking\n",
    "es_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegressionCV(), n_jobs=N_JOBS)\n",
    "es_clf.fit(X_train, y_train)\n",
    "es_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc64f72d-a6b9-405e-8f2d-de689861a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSEMBLE - Bagging\n",
    "eb_clf = BaggingClassifier(LogisticRegressionCV(), n_jobs=N_JOBS)\n",
    "eb_clf.fit(X_train, y_train)\n",
    "eb_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33e70eb-1344-45e1-9a1e-cc39be68bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full pipeline at once!\n",
    "# (Once the corresponding cells have been executed at least once).\n",
    "\n",
    "train_df = extract_features(fe.extract_features_minimal, train_data)\n",
    "remove_bogus_line(train_df, 4877)\n",
    "X_train = define_X_y(train_df)\n",
    "X_train, X_test, y_train, y_test = split(X_train, train_df, 0.2, shuffle=True)\n",
    "models = set_model()\n",
    "test_models(X_train, y_train, X_test, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da278fce-1287-42e6-b0e5-ffabf51ed7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
